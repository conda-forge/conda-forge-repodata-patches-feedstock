# from this bit of code
# if record_name == "pyarrow" and record.get('timestamp', 0) < 1675198779000:
#     if not any(dep.split(' ')[0] == "arrow-cpp-proc" for dep in record.get('constrains', ())):
#         if 'constrains' in record:
#             record['constrains'].append("arrow-cpp-proc * cpu")
#         else:
#             record['constrains'] = ["arrow-cpp-proc * cpu"]
if:
  name: pyarrow
  timestamp_lt: 1675198779000
  not_has_constrains: arrow-cpp-proc?( *)
then:
  - add_constrains: arrow-cpp-proc * cpu
---
# from this bit of code
# if record_name == "pyarrow" and record.get('timestamp', 0) < 1675198779000:
#     # pyarrow builds done with numpy<1.16.6 are incompatible with numpy 1.20
#     # We have been building with numpy 1.16.6 since 1612266172867
#     # The underlying issue is https://github.com/numpy/numpy/issues/17913
#     if record.get('timestamp', 0) < 1607959235411 and any(dep.split(' ')[0] == 'numpy'
#         for dep in record.get('depends', ())):
#         _pin_stricter(fn, record, "numpy", "x", "1.20")
if:
  name: pyarrow
  timestamp_lt: 1607959235411  # smaller of the two stamps above
  has_depends: numpy?( *)
then:
  - tighten_depends:
      name: numpy
      max_pin: x
      upper_bound: "1.20"
---
# Prior to Pyarrow 15.0.0 the pandas_compat code made use of pandas.core.internals.DatetimeTZBlock,
# which will no longer be exposed as of Pandas 3. This means that converting a Table to a Dataframe
# using Pyarrow<15.0.0 and Pandas>=3 will result in an AttributeError. Therefore, we constrain the
# Pandas version to less than 3 if the Pyarrow version is less than 15.
# DatetimeTZBlock no longer exposed: https://github.com/pandas-dev/pandas/pull/58467/
# Usage of DatetimeTZBlock removed: https://github.com/apache/arrow/pull/38321
if:
  name: pyarrow
  timestamp_lt: 1715513055000  # Sun 12 May 2024 11:24:15 GMT
  version_lt: 15.0.0
  not_has_constrains: pandas?( *)
then:
  - add_constrains: pandas <=3.0a0
