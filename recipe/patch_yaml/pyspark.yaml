# pyspark is not compatible with numpy 2.0 yet; see
# https://github.com/conda-forge/pyspark-feedstock/pull/51
if:
  name: pyspark
  subdir_in: noarch
  timestamp_lt: 1729807935403
then:
  - tighten_depends:
      name: numpy
      upper_bound: "2.0"
